{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12b1a78a-7bec-46ea-84f3-26782ab09084",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "os.environ['TORCH_USE_CUDA_DSA']   = \"1\"\n",
    "from os import path as osp\n",
    "# if 'jupyter' in os.getcwd():\n",
    "#     os.chdir(osp.join(os.getcwd(), 'masterarbeit', 'code'))\n",
    "import glob\n",
    "import time\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm as tqdmnotebook\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from typing import Any\n",
    "from typing import Callable\n",
    "from typing import Optional\n",
    "from typing import Tuple\n",
    "from typing import Union\n",
    "from typing import Dict\n",
    "from typing import List\n",
    "from itertools import cycle\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "mpl.rc('axes', unicode_minus=False)\n",
    "preamble = r'\\usepackage{amsmath}'  # LaTeX preamble command\n",
    "mpl.rcParams['text.latex.preamble'] = preamble\n",
    "\n",
    "# import seaborn as sns\n",
    "import networkx as nx\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "import gc\n",
    "\n",
    "# pytorch imports\n",
    "import torch\n",
    "from torch import Tensor, nn, cuda\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import random_split\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "# pytorch geometric imports\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.transforms import Compose\n",
    "\n",
    "# lightning imports\n",
    "from lightning.pytorch.utilities.combined_loader import CombinedLoader\n",
    "\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "from google.cloud import storage\n",
    "\n",
    "import sys\n",
    "# Add the 'code' directory to sys.path to make the  submodules available\n",
    "# sys.path.append('/home/jupyter/masterarbeit/code')\n",
    "\n",
    "from util.utils import generate_log_name\n",
    "from util.plot_utils import *\n",
    "\n",
    "import logging as log\n",
    "\n",
    "from data.dataset.GraphDataset import GraphDataset\n",
    "\n",
    "from model.transform import CollapseChannels, ExtractSquare\n",
    "from model.autoencoder import Autoencoder\n",
    "from model.predictor import Predictor\n",
    "from model.DAN import GradientReversalLayer, DomainDiscriminator\n",
    "\n",
    "from model.criterions import WeightedMSELoss, MSLELoss, FocalLoss, ZeroInflatedLoss, CustomHuberLoss\n",
    "\n",
    "from fullmodel import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83312120-e8ef-4639-a2b5-91cbe8c8c79a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "exp_id='exp08'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3706c5f2-674c-45d5-be60-93b32640da05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NUM_WORKERS: int = 0\n",
    "BATCH_SIZE: int = 64\n",
    "NUM_CHANNELS: int = 2\n",
    "WDW_LENGTH: list = [12, 6]\n",
    "\n",
    "# Constants that I may change a bit during testing\n",
    "tgt: str = 'MELBOURNE'\n",
    "src_list: list = ['ANTWERP']\n",
    "# src_list: list = ['ANTWERP', 'BANGKOK', 'BARCELONA', 'BERLIN', 'CHICAGO', 'ISTANBUL', 'MOSCOW'] # 7 cities\n",
    "EPOCHS: int = 2\n",
    "tgt_data_limit: int = 1680\n",
    "src_data_limit: int = None\n",
    "LOGGING: int = 1\n",
    "\n",
    "if src_data_limit == -1:\n",
    "    src_data_limit = None\n",
    "\n",
    "# Get data from bucket\n",
    "bucket_name = 'cloud-ai-platform-054ad037-69b6-4c4d-94a1-75d2591213c7'\n",
    "bucket_folder = 'data/graphs'\n",
    "local_folder  = 'data/graphs'\n",
    "download_directory(bucket_name, bucket_folder, local_folder)\n",
    "bucket_folder = 'data/raw'\n",
    "local_folder  = 'data/raw'\n",
    "download_directory(bucket_name, bucket_folder, local_folder)\n",
    "\n",
    "bucket_output = 'output/models/'\n",
    "\n",
    "# Constants that I don't intend to change much\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "TRAIN_VAL_TEST_SPLIT = [0.8, 0.1, 0.1]\n",
    "\n",
    "pre_transform = Compose([\n",
    "    CollapseChannels(),\n",
    "    ExtractSquare(50, 'central'),\n",
    "])\n",
    "\n",
    "static_transform = Compose([\n",
    "    ExtractSquare(50, 'central'),\n",
    "])\n",
    "\n",
    "ds_kwargs = {\n",
    "    'root_dir': 'data/raw',\n",
    "    'device': device,\n",
    "    'pre_transform': pre_transform,\n",
    "    'static_transform': static_transform,\n",
    "}\n",
    "\n",
    "# seed generator for DataLoader\n",
    "torch.manual_seed(2311)\n",
    "\n",
    "# Create datasets for each city\n",
    "ds_dict = {}\n",
    "for city in src_list:\n",
    "    ds_dict[city] = GraphDataset(\n",
    "        cities=[city],\n",
    "        limit=src_data_limit,\n",
    "        **ds_kwargs,\n",
    "    )\n",
    "    \n",
    "temp_tgt = GraphDataset(\n",
    "    cities=[tgt],\n",
    "    limit=None,\n",
    "    **ds_kwargs,\n",
    ")\n",
    "\n",
    "train_tgt, val_tgt, test_tgt = random_split(\n",
    "    temp_tgt, [0.08, 0.08, 0.84]\n",
    ")\n",
    "\n",
    "\n",
    "train_tgt = DataLoader(train_tgt, batch_size=BATCH_SIZE, shuffle=True,  drop_last=True)\n",
    "val_tgt   = DataLoader(  val_tgt, batch_size=BATCH_SIZE, shuffle=True,  drop_last=True)\n",
    "test_tgt  = DataLoader( test_tgt, batch_size=BATCH_SIZE, shuffle=False, drop_last=True)\n",
    "# Split each dataset into training and test sets\n",
    "train = {}\n",
    "val   = {}\n",
    "test  = {}\n",
    "for city in ds_dict:\n",
    "    train_ds, val_ds, test_ds = random_split(\n",
    "        ds_dict[city], TRAIN_VAL_TEST_SPLIT\n",
    "    )\n",
    "    train[city] = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,  drop_last=True)\n",
    "    val[city]   = DataLoader(  val_ds, batch_size=BATCH_SIZE, shuffle=True,  drop_last=True)\n",
    "    test[city]  = DataLoader( test_ds, batch_size=BATCH_SIZE, shuffle=False, drop_last=True)\n",
    "\n",
    "train[tgt] = train_tgt\n",
    "val[tgt]   = val_tgt\n",
    "test[tgt]  = test_tgt\n",
    "\n",
    "# Create dataloader for offline training with source cities\n",
    "source_train = {city: train[city] for city in src_list}\n",
    "source_dataloader = CombinedLoader(source_train, mode='max_size_cycle')\n",
    "\n",
    "source_test = {city: test[city] for city in src_list}\n",
    "sourcetest_dataloader = CombinedLoader(source_test, mode='max_size_cycle')\n",
    "\n",
    "target_dataloader = CombinedLoader({tgt: train[tgt]}, mode='max_size_cycle')\n",
    "targettest_dataloader = CombinedLoader({tgt: test[tgt]}, mode='max_size_cycle')\n",
    "\n",
    "# Create dataloader for online training with source and target cities\n",
    "train_dataloader = CombinedLoader(train, mode='max_size_cycle')\n",
    "\n",
    "# Create dataloader for validation with source and target cities\n",
    "val_dataloader = CombinedLoader(val, mode='max_size_cycle')\n",
    "\n",
    "# Create dataloader for testing with source and target cities\n",
    "test_dataloader = CombinedLoader(test, mode='max_size_cycle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eca4083-1f0b-4d20-a86d-8c9d13a17c65",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "483aab54571844c48c963f4d550eab58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/2 [00:00<?,?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<tqdm.notebook.tqdm_notebook at 0x7fbac61bc280>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85ebc501b75e4e6fab28886f465ff61a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/541 [00:00<?,?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<tqdm.notebook.tqdm_notebook at 0x7fbac61bccd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##############################################################################\n",
    "########################## INSTANTIATING THE MODEL ###########################\n",
    "##############################################################################\n",
    "AE_K_CHEB = 3\n",
    "AE_CONV_DIM = 16\n",
    "AE_LINEAR_DIM = 8\n",
    "AE_DROPOUT = 0.5\n",
    "AE_ACTIVATION = 'tanh'\n",
    "\n",
    "AE_parameters = {\n",
    "    'K_cheb': AE_K_CHEB,\n",
    "    'conv_dim': AE_CONV_DIM,\n",
    "    'linear_dim': AE_LINEAR_DIM,\n",
    "    'dropout': AE_DROPOUT,\n",
    "    'activation': AE_ACTIVATION,\n",
    "    'num_channels': NUM_CHANNELS,\n",
    "    'device': device,\n",
    "}\n",
    "\n",
    "DD_SEQ_LEN = 12\n",
    "DD_FEAT_DIM = AE_LINEAR_DIM\n",
    "DD_LEFT_NODES = 1750\n",
    "DD_parameters = {\n",
    "    'seq_len': DD_SEQ_LEN,\n",
    "    'feat_dim': DD_FEAT_DIM,\n",
    "    'left_nodes': DD_LEFT_NODES,\n",
    "}\n",
    "\n",
    "# autoencoder linear dims + 4 sin-cos time features\n",
    "PRED_FEATURES   = AE_LINEAR_DIM + 4\n",
    "PRED_LINEAR_DIM = 32\n",
    "PRED_PERIODS_IN = 12\n",
    "PRED_PERIODS_OUT = [0, 1, 2, 5, 8, 11]\n",
    "PRED_ACTIVATION  = 'relu'\n",
    "\n",
    "PR_parameters = {\n",
    "    'features': PRED_FEATURES,\n",
    "    'linear_dim': PRED_LINEAR_DIM,\n",
    "    'periods_in': PRED_PERIODS_IN,\n",
    "    'periods_out': PRED_PERIODS_OUT,\n",
    "    'activation': PRED_ACTIVATION,\n",
    "    'num_channels': NUM_CHANNELS,\n",
    "    'device': device,\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    \n",
    "}\n",
    "num_epochs = EPOCHS\n",
    "dataloaders = train_dataloader, target_dataloader, targettest_dataloader\n",
    "AE_criterion = nn.MSELoss()\n",
    "PR_criterion = nn.MSELoss()\n",
    "optimizer_parameters = 5e-4, 5e-5\n",
    "BATCH_SIZE = BATCH_SIZE\n",
    "dd_lambda = 0.1\n",
    "\n",
    "folder = osp.join('training logs', 'models', exp_id)\n",
    "check_dir(folder)\n",
    "\n",
    "linear_dims = [8, 16, 32, 64]\n",
    "test_errors = {}\n",
    "for i, linear_dim in enumerate(linear_dims):\n",
    "    PR_parameters['linear_dim'] = linear_dim\n",
    "    model = Model(\n",
    "        AE_parameters=AE_parameters,\n",
    "        DD_parameters=DD_parameters,\n",
    "        PR_parameters=PR_parameters,\n",
    "        num_epochs=num_epochs,\n",
    "        dataloaders=dataloaders,\n",
    "        AE_criterion=AE_criterion,\n",
    "        PR_criterion=PR_criterion,\n",
    "        optimizer_parameters=optimizer_parameters,\n",
    "        BATCH_SIZE=BATCH_SIZE,\n",
    "        dd_lambda=dd_lambda,\n",
    "        folder=folder,\n",
    "        specs=f'{linear_dim}',\n",
    "        tgt=tgt,\n",
    "        val_dl=val_dataloader\n",
    "    ).to(device)\n",
    "    \n",
    "    if i == 0:\n",
    "        model.ae_train('pretrain', save=False, lambda_update=1.5, plot=1)\n",
    "        model.ae_train('finetune', save=True, plot=1)\n",
    "    else:\n",
    "        model.load_module('autoencoder', folder, 'ae_8.pth')\n",
    "            \n",
    "    model.pred_train('pretrain', save=False)\n",
    "    model.pred_train('finetune', save=True)\n",
    "    \n",
    "    errors = model.pred_test()\n",
    "    test_errors[linear_dim] = errors\n",
    "    plot_losses_boxplot(\n",
    "        test_errors, \n",
    "        'Linear Dimension', \n",
    "        save=False, \n",
    "        exp_id=exp_id,\n",
    "    )\n",
    "\n",
    "plot_losses_boxplot(\n",
    "    test_errors, \n",
    "    'Linear Dimension', \n",
    "    save=True,\n",
    "    exp_id=exp_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cff4a05-d277-40b3-9c5d-d962452193db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": ".m113",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/:m113"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
