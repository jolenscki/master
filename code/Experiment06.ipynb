{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d78faa31-2b19-49f1-9872-05c40cc323a8",
   "metadata": {},
   "source": [
    "# Experiment 06: Domain Adaptation on the autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12b1a78a-7bec-46ea-84f3-26782ab09084",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os import path as osp\n",
    "# if 'jupyter' in os.getcwd():\n",
    "#     os.chdir(osp.join(os.getcwd(), 'masterarbeit', 'code'))\n",
    "import glob\n",
    "import time\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm as tqdmnotebook\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from typing import Any\n",
    "from typing import Callable\n",
    "from typing import Optional\n",
    "from typing import Tuple\n",
    "from typing import Union\n",
    "from typing import Dict\n",
    "from typing import List\n",
    "from itertools import cycle\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "mpl.rc('axes', unicode_minus=False)\n",
    "preamble = r'\\usepackage{amsmath}'  # LaTeX preamble command\n",
    "mpl.rcParams['text.latex.preamble'] = preamble\n",
    "\n",
    "# import seaborn as sns\n",
    "import networkx as nx\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "# pytorch imports\n",
    "import torch\n",
    "from torch import Tensor, nn, cuda\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import random_split\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "# pytorch geometric imports\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.transforms import Compose\n",
    "\n",
    "from torch_geometric_temporal import GConvLSTM\n",
    "\n",
    "# lightning imports\n",
    "from lightning.pytorch.utilities.combined_loader import CombinedLoader\n",
    "\n",
    "from google.cloud import storage\n",
    "\n",
    "import sys\n",
    "# Add the 'code' directory to sys.path to make the  submodules available\n",
    "# sys.path.append('/home/jupyter/masterarbeit/code')\n",
    "\n",
    "from util.utils import generate_log_name\n",
    "from util.plot_utils import *\n",
    "\n",
    "import logging as log\n",
    "\n",
    "from data.dataset.GraphDataset import GraphDataset\n",
    "\n",
    "from model.transform import CollapseChannels, ExtractSquare\n",
    "from model.autoencoder import Autoencoder\n",
    "\n",
    "from model.criterions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af9f23d2-f9de-42ef-8049-8015d230009b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "exp_id = 'exp06'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a88132c3-aa06-4346-9298-283280e25611",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NUM_WORKERS: int = 0\n",
    "BATCH_SIZE: int = 32\n",
    "NUM_CHANNELS: int = 2\n",
    "WDW_LENGTH: list = [12, 6]\n",
    "\n",
    "# Constants that I may change a bit during testing\n",
    "tgt: str = 'MELBOURNE'\n",
    "src_list: list = ['ANTWERP']\n",
    "# src_list: list = ['ANTWERP', 'BANGKOK', 'BARCELONA', 'BERLIN', 'CHICAGO', 'ISTANBUL', 'MOSCOW'] # 7 cities\n",
    "EPOCHS_OFFLINE: int = 4\n",
    "tgt_data_limit: int = 1680\n",
    "src_data_limit: int = None\n",
    "LOGGING: int = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4e7122a-8e66-41b8-b117-cd8b1b4dc088",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if src_data_limit == -1:\n",
    "    src_data_limit = None\n",
    "\n",
    "# Get data from bucket\n",
    "bucket_name = 'cloud-ai-platform-054ad037-69b6-4c4d-94a1-75d2591213c7'\n",
    "bucket_folder = 'data/graphs'\n",
    "local_folder  = 'data/graphs'\n",
    "download_directory(bucket_name, bucket_folder, local_folder)\n",
    "bucket_folder = 'data/raw'\n",
    "local_folder  = 'data/raw'\n",
    "download_directory(bucket_name, bucket_folder, local_folder)\n",
    "\n",
    "bucket_output = 'output/models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5b1fbc7-14f3-4942-98a7-129b74e2a53d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Constants that I don't intend to change much\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "TRAIN_VAL_TEST_SPLIT = [0.8, 0.1, 0.1]\n",
    "\n",
    "pre_transform = Compose([\n",
    "    CollapseChannels(),\n",
    "    ExtractSquare(50, 'central'),\n",
    "])\n",
    "\n",
    "static_transform = Compose([\n",
    "    ExtractSquare(50, 'central'),\n",
    "])\n",
    "\n",
    "ds_kwargs = {\n",
    "    'root_dir': 'data/raw',\n",
    "    'device': device,\n",
    "    'pre_transform': pre_transform,\n",
    "    'static_transform': static_transform,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f85cb87-32d3-4f64-b06b-09a46793e98b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# seed generator for DataLoader\n",
    "torch.manual_seed(2311)\n",
    "\n",
    "# Create datasets for each city\n",
    "ds_dict = {}\n",
    "for city in src_list:\n",
    "    ds_dict[city] = GraphDataset(\n",
    "        cities=[city],\n",
    "        limit=src_data_limit,\n",
    "        **ds_kwargs,\n",
    "    )\n",
    "    \n",
    "ds_dict[tgt] = GraphDataset(\n",
    "    cities=[tgt],\n",
    "    limit=tgt_data_limit,\n",
    "    **ds_kwargs,\n",
    ")\n",
    "\n",
    "# Split each dataset into training and test sets\n",
    "train = {}\n",
    "val   = {}\n",
    "test  = {}\n",
    "for city in ds_dict:\n",
    "    train_ds, val_ds, test_ds = random_split(\n",
    "        ds_dict[city], TRAIN_VAL_TEST_SPLIT\n",
    "    )\n",
    "    train[city] = DataLoader(train_ds, batch_size=BATCH_SIZE,  shuffle=True)\n",
    "    val[city]   = DataLoader(  val_ds, batch_size=BATCH_SIZE,  shuffle=True)\n",
    "    test[city]  = DataLoader( test_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Create dataloader for offline training with source cities\n",
    "source_train = {city: train[city] for city in src_list}\n",
    "source_dataloader = CombinedLoader(source_train, mode='max_size_cycle')\n",
    "\n",
    "source_test = {city: test[city] for city in src_list}\n",
    "sourcetest_dataloader = CombinedLoader(source_test, mode='max_size_cycle')\n",
    "\n",
    "target_dataloader = CombinedLoader({tgt: train[tgt]}, mode='max_size_cycle')\n",
    "targettest_dataloader = CombinedLoader({tgt: test[tgt]}, mode='max_size_cycle')\n",
    "\n",
    "# # Create dataloader for online training with source and target cities\n",
    "# train_dataloader = CombinedLoader(train, mode='max_size_cycle')\n",
    "\n",
    "# # Create dataloader for validation with source and target cities\n",
    "# val_dataloader = CombinedLoader(val, mode='max_size_cycle')\n",
    "\n",
    "# # Create dataloader for testing with source and target cities\n",
    "# test_dataloader = CombinedLoader(test, mode='max_size_cycle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34e909c6-10ed-4a01-b027-d694328ca9f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "############################# DEFINE AUTOENCODER #############################\n",
    "##############################################################################\n",
    "AE_CONV_DIM      = 16\n",
    "AE_LINEAR_DIM    =  8\n",
    "AE_ACTIVATION    = 'tanh'\n",
    "AE_DROPOUT       = 0.5\n",
    "AE_K_CHEB        = 3\n",
    "\n",
    "ae = Autoencoder(\n",
    "    conv_dim=AE_CONV_DIM,\n",
    "    num_channels=NUM_CHANNELS,\n",
    "    K_cheb=AE_K_CHEB,\n",
    "    device=device,\n",
    "    activation=AE_ACTIVATION,\n",
    "    dropout=AE_DROPOUT,\n",
    "    linear_dim=AE_LINEAR_DIM,\n",
    "    ).to(device)\n",
    "\n",
    "##############################################################################\n",
    "EPOCHS = 2\n",
    "pt_dataloader = source_dataloader\n",
    "ft_dataloader = target_dataloader\n",
    "test_dataloader = targettest_dataloader\n",
    "\n",
    "AE_criterion = nn.MSELoss()\n",
    "\n",
    "test_losses_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a058cdff-e01d-432b-90f4-3f5a7d782df0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad3792c54045456e88b7c5799e06aebe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/2 [00:00<?,?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a04cb47e1d804ad5a7d03663d193b4bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/43 [00:00<?,?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43eec99ee0a848b7928d3c799c13a718",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/43 [00:00<?,?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acf3cd914e844836aa846f9eb73785e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/43 [00:00<?,?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##############################################################################\n",
    "######################## AUTOENCODER TARGET ONLY #############################\n",
    "##############################################################################\n",
    "lr = 5e-3\n",
    "l2_decay = 5e-4\n",
    "optimizer = torch.optim.Adam(\n",
    "    [\n",
    "        {\n",
    "            'params': ae.parameters(),\n",
    "        }\n",
    "    ], lr=lr, weight_decay=l2_decay\n",
    ")\n",
    "scaler = GradScaler()\n",
    "\n",
    "tqdm_fmt = ('{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining},'\n",
    "                '{rate_fmt}{postfix}]')\n",
    "tqdm_epoch = {'total': EPOCHS, 'leave': True, 'desc': 'Epochs',\n",
    "              'colour': 'blue', 'bar_format': tqdm_fmt}\n",
    "tqdm_batch = {'total': ft_dataloader._dataset_length()//BATCH_SIZE + 1,\n",
    "              'leave': True, 'desc': 'Batches', 'colour': 'green',\n",
    "              'bar_format': tqdm_fmt}\n",
    "\n",
    "ae.train()\n",
    "with tqdmnotebook(**tqdm_epoch) as pbar_epochs:\n",
    "    for epoch in range(EPOCHS):\n",
    "        with tqdmnotebook(**tqdm_batch) as pbar_batches:\n",
    "            for databatch, i, _ in ft_dataloader:\n",
    "                total_loss = 0\n",
    "                for city, data in databatch.items():\n",
    "                    x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "                    with torch.cuda.amp.autocast():\n",
    "                        x_recons = ae(x, edge_index)\n",
    "                        x = x.reshape(x_recons.shape)\n",
    "                        loss = AE_criterion(x_recons, x)\n",
    "                    total_loss += loss\n",
    "                scaler.scale(total_loss).backward(retain_graph=True)\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "                pbar_batches.update(1)\n",
    "            pbar_epochs.update(1)\n",
    "            \n",
    "folder = osp.join('training logs', 'models', exp_id)\n",
    "check_dir(folder)\n",
    "torch.save(ae.state_dict(), osp.join(folder, 'ae_target_only.pth'))\n",
    "\n",
    "            \n",
    "ae.eval()\n",
    "errors = {\n",
    "    'MAE': torch.empty(0, device=device, dtype=torch.float16), \n",
    "    'MSE': torch.empty(0, device=device, dtype=torch.float16)\n",
    "}\n",
    "with torch.no_grad(), tqdmnotebook(**tqdm_batch) as pbar_batches:\n",
    "    for databatch, i, _ in test_dataloader:\n",
    "        for city, data in databatch.items():\n",
    "            x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "            batch_size = int(data.ptr.shape[0] - 1)\n",
    "            x_recons = ae(x, edge_index)\n",
    "\n",
    "            x = x.reshape(batch_size, -1)\n",
    "            x_recons = x_recons.reshape(batch_size, -1)\n",
    "\n",
    "            mae = torch.mean(torch.abs(x - x_recons), dim=1)\n",
    "            mse = torch.mean(torch.square(x - x_recons), dim=1)\n",
    "\n",
    "            errors['MAE'] = torch.cat([errors['MAE'], mae], dim=0)\n",
    "            errors['MSE'] = torch.cat([errors['MSE'], mse], dim=0)\n",
    "            \n",
    "        test_losses_dict['Target Only'] = errors\n",
    "        pbar_batches.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a5cc42c-4c2a-40ae-8b82-0ecef8fe2eea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "############################# DEFINE AUTOENCODER #############################\n",
    "##############################################################################\n",
    "AE_CONV_DIM      = 16\n",
    "AE_LINEAR_DIM    =  8\n",
    "AE_ACTIVATION    = 'relu'\n",
    "AE_DROPOUT       = 0.5\n",
    "AE_K_CHEB        = 3\n",
    "\n",
    "ae = Autoencoder(\n",
    "    conv_dim=AE_CONV_DIM,\n",
    "    num_channels=NUM_CHANNELS,\n",
    "    K_cheb=AE_K_CHEB,\n",
    "    device=device,\n",
    "    activation=AE_ACTIVATION,\n",
    "    dropout=AE_DROPOUT,\n",
    "    linear_dim=AE_LINEAR_DIM,\n",
    "    ).to(device)\n",
    "\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8f342c2-574d-44ca-abd1-c28280da37fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dbb93450a534087b9a6305086cd20eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/2 [00:00<?,?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fd33c9a0eae451c81c0ca1ac2f8ff9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1081 [00:00<?,?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d41bdf91cdc416d8fd10febd8b71fe7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1081 [00:00<?,?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6855872af8440a3a36671f09e7da6e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/2 [00:00<?,?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5cad8ea24054262a345541284c5ebea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/43 [00:00<?,?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a149fc285a745d6b47d10878527afdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/43 [00:00<?,?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25ed7af9993147f799b88cd0fde1738b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/43 [00:00<?,?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##############################################################################\n",
    "######################### AUTOENCODER PRETRAINING ############################\n",
    "##############################################################################\n",
    "lr = 5e-3\n",
    "l2_decay = 5e-4\n",
    "optimizer = torch.optim.Adam(\n",
    "    [\n",
    "        {\n",
    "            'params': ae.parameters(),\n",
    "        }\n",
    "    ], lr=lr, weight_decay=l2_decay\n",
    ")\n",
    "scaler = GradScaler()\n",
    "\n",
    "tqdm_fmt = ('{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining},'\n",
    "                '{rate_fmt}{postfix}]')\n",
    "tqdm_epoch = {'total': EPOCHS, 'leave': True, 'desc': 'Epochs',\n",
    "              'colour': 'blue', 'bar_format': tqdm_fmt}\n",
    "tqdm_batch = {'total': pt_dataloader._dataset_length()//BATCH_SIZE + 1,\n",
    "              'leave': True, 'desc': 'Batches', 'colour': 'green',\n",
    "              'bar_format': tqdm_fmt}\n",
    "\n",
    "ae.train()\n",
    "with tqdmnotebook(**tqdm_epoch) as pbar_epochs:\n",
    "    for epoch in range(EPOCHS):\n",
    "        with tqdmnotebook(**tqdm_batch) as pbar_batches:\n",
    "            for databatch, i, _ in pt_dataloader:\n",
    "                total_loss = 0\n",
    "                for city, data in databatch.items():\n",
    "                    x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "                    with torch.cuda.amp.autocast():\n",
    "                        x_recons = ae(x, edge_index)\n",
    "                        x = x.reshape(x_recons.shape)\n",
    "                        loss = AE_criterion(x_recons, x)\n",
    "                    total_loss += loss\n",
    "                scaler.scale(total_loss).backward(retain_graph=True)\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "                pbar_batches.update(1)\n",
    "            pbar_epochs.update(1)\n",
    "\n",
    "##############################################################################\n",
    "######################### AUTOENCODER FINETUNING #############################\n",
    "##############################################################################\n",
    "lr = 1e-4\n",
    "l2_decay = 1e-5\n",
    "optimizer = torch.optim.Adam(\n",
    "    [\n",
    "        {\n",
    "            'params': ae.parameters(),\n",
    "        }\n",
    "    ], lr=lr, weight_decay=l2_decay\n",
    ")\n",
    "scaler = GradScaler()\n",
    "\n",
    "tqdm_fmt = ('{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining},'\n",
    "                '{rate_fmt}{postfix}]')\n",
    "tqdm_epoch = {'total': EPOCHS, 'leave': True, 'desc': 'Epochs',\n",
    "              'colour': 'blue', 'bar_format': tqdm_fmt}\n",
    "tqdm_batch = {'total': ft_dataloader._dataset_length()//BATCH_SIZE + 1,\n",
    "              'leave': True, 'desc': 'Batches', 'colour': 'green',\n",
    "              'bar_format': tqdm_fmt}\n",
    "\n",
    "ae.train()\n",
    "with tqdmnotebook(**tqdm_epoch) as pbar_epochs:\n",
    "    for epoch in range(EPOCHS):\n",
    "        with tqdmnotebook(**tqdm_batch) as pbar_batches:\n",
    "            for databatch, i, _ in ft_dataloader:\n",
    "                total_loss = 0\n",
    "                for city, data in databatch.items():\n",
    "                    x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "                    with torch.cuda.amp.autocast():\n",
    "                        x_recons = ae(x, edge_index)\n",
    "                        x = x.reshape(x_recons.shape)\n",
    "                        loss = AE_criterion(x_recons, x)\n",
    "                    total_loss += loss\n",
    "                scaler.scale(total_loss).backward(retain_graph=True)\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "                pbar_batches.update(1)\n",
    "            pbar_epochs.update(1)\n",
    "\n",
    "folder = osp.join('training logs', 'models', exp_id)\n",
    "check_dir(folder)\n",
    "torch.save(ae.state_dict(), osp.join(folder, f'ae_pretrained_1.pth'))\n",
    "\n",
    "ae.eval()\n",
    "errors = {\n",
    "    'MAE': torch.empty(0, device=device, dtype=torch.float16), \n",
    "    'MSE': torch.empty(0, device=device, dtype=torch.float16)\n",
    "}\n",
    "with torch.no_grad(), tqdmnotebook(**tqdm_batch) as pbar_batches:\n",
    "    for databatch, i, _ in test_dataloader:\n",
    "        for city, data in databatch.items():\n",
    "            x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "            batch_size = int(data.ptr.shape[0] - 1)\n",
    "            x_recons = ae(x, edge_index)\n",
    "\n",
    "            x = x.reshape(batch_size, -1)\n",
    "            x_recons = x_recons.reshape(batch_size, -1)\n",
    "\n",
    "            mae = torch.mean(torch.abs(x - x_recons), dim=1)\n",
    "            mse = torch.mean(torch.square(x - x_recons), dim=1)\n",
    "\n",
    "            errors['MAE'] = torch.cat([errors['MAE'], mae], dim=0)\n",
    "            errors['MSE'] = torch.cat([errors['MSE'], mse], dim=0)\n",
    "            \n",
    "        test_losses_dict['Pre-trained w/ 1 source'] = errors\n",
    "        pbar_batches.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6295f9b8-da00-4996-9994-a1a90870ec74",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 800x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_losses_boxplot(test_losses_dict, variable=r'Pre-training', \n",
    "                    errors=['MAE', 'MSE'], specs=\"\", save=True, show=True,\n",
    "                    exp_id=exp_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d0802b1-aa64-492b-905c-d48b78bb2560",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "############################# DEFINE AUTOENCODER #############################\n",
    "##############################################################################\n",
    "AE_CONV_DIM      = 16\n",
    "AE_LINEAR_DIM    =  8\n",
    "AE_ACTIVATION    = 'relu'\n",
    "AE_DROPOUT       = 0.5\n",
    "AE_K_CHEB        = 3\n",
    "\n",
    "ae = Autoencoder(\n",
    "    conv_dim=AE_CONV_DIM,\n",
    "    num_channels=NUM_CHANNELS,\n",
    "    K_cheb=AE_K_CHEB,\n",
    "    device=device,\n",
    "    activation=AE_ACTIVATION,\n",
    "    dropout=AE_DROPOUT,\n",
    "    linear_dim=AE_LINEAR_DIM,\n",
    "    ).to(device)\n",
    "\n",
    "##############################################################################\n",
    "src_list: list = ['ANTWERP', 'BANGKOK']\n",
    "\n",
    "# seed generator for DataLoader\n",
    "torch.manual_seed(2311)\n",
    "\n",
    "# Create datasets for each city\n",
    "ds_dict = {}\n",
    "for city in src_list:\n",
    "    ds_dict[city] = GraphDataset(\n",
    "        cities=[city],\n",
    "        limit=src_data_limit,\n",
    "        **ds_kwargs,\n",
    "    )\n",
    "    \n",
    "ds_dict[tgt] = GraphDataset(\n",
    "    cities=[tgt],\n",
    "    limit=tgt_data_limit,\n",
    "    **ds_kwargs,\n",
    ")\n",
    "\n",
    "# Split each dataset into training and test sets\n",
    "train = {}\n",
    "val   = {}\n",
    "test  = {}\n",
    "for city in ds_dict:\n",
    "    train_ds, val_ds, test_ds = random_split(\n",
    "        ds_dict[city], TRAIN_VAL_TEST_SPLIT\n",
    "    )\n",
    "    train[city] = DataLoader(train_ds, batch_size=BATCH_SIZE,  shuffle=True)\n",
    "    val[city]   = DataLoader(  val_ds, batch_size=BATCH_SIZE,  shuffle=True)\n",
    "    test[city]  = DataLoader( test_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Create dataloader for offline training with source cities\n",
    "source_train = {city: train[city] for city in src_list}\n",
    "source_dataloader = CombinedLoader(source_train, mode='max_size_cycle')\n",
    "\n",
    "source_test = {city: test[city] for city in src_list}\n",
    "sourcetest_dataloader = CombinedLoader(source_test, mode='max_size_cycle')\n",
    "\n",
    "target_dataloader = CombinedLoader({tgt: train[tgt]}, mode='max_size_cycle')\n",
    "targettest_dataloader = CombinedLoader({tgt: test[tgt]}, mode='max_size_cycle')\n",
    "##############################################################################\n",
    "pt_dataloader = source_dataloader\n",
    "ft_dataloader = target_dataloader\n",
    "test_dataloader = targettest_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c423a8a4-e7c4-4f4d-a9f0-16298e6547b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8b76c4c6336407d85431bbb8914276e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/2 [00:00<?,?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba05144dea5a49a38e80f2dd6b611e21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1081 [00:00<?,?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f63d0f5df084a069515fb4f1edb3c0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1081 [00:00<?,?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "697f19e863854cf18e04d079cbc9de0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/2 [00:00<?,?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69bb0353d36e4bf396e80eb341680c7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/43 [00:00<?,?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "773dfaab6f3a4e1b8308cf1da27c1f68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/43 [00:00<?,?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6096818b64034c629ae1a2bcc5114b3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/43 [00:00<?,?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##############################################################################\n",
    "######################### AUTOENCODER PRETRAINING ############################\n",
    "##############################################################################\n",
    "lr = 5e-3\n",
    "l2_decay = 5e-4\n",
    "optimizer = torch.optim.Adam(\n",
    "    [\n",
    "        {\n",
    "            'params': ae.parameters(),\n",
    "        }\n",
    "    ], lr=lr, weight_decay=l2_decay\n",
    ")\n",
    "scaler = GradScaler()\n",
    "\n",
    "tqdm_fmt = ('{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining},'\n",
    "                '{rate_fmt}{postfix}]')\n",
    "tqdm_epoch = {'total': EPOCHS, 'leave': True, 'desc': 'Epochs',\n",
    "              'colour': 'blue', 'bar_format': tqdm_fmt}\n",
    "tqdm_batch = {'total': pt_dataloader._dataset_length()//BATCH_SIZE + 1,\n",
    "              'leave': True, 'desc': 'Batches', 'colour': 'green',\n",
    "              'bar_format': tqdm_fmt}\n",
    "\n",
    "ae.train()\n",
    "with tqdmnotebook(**tqdm_epoch) as pbar_epochs:\n",
    "    for epoch in range(EPOCHS):\n",
    "        with tqdmnotebook(**tqdm_batch) as pbar_batches:\n",
    "            for databatch, i, _ in pt_dataloader:\n",
    "                total_loss = 0\n",
    "                for city, data in databatch.items():\n",
    "                    x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "                    with torch.cuda.amp.autocast():\n",
    "                        x_recons = ae(x, edge_index)\n",
    "                        x = x.reshape(x_recons.shape)\n",
    "                        loss = AE_criterion(x_recons, x)\n",
    "                    total_loss += loss\n",
    "                scaler.scale(total_loss).backward(retain_graph=True)\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "                pbar_batches.update(1)\n",
    "            pbar_epochs.update(1)\n",
    "\n",
    "##############################################################################\n",
    "######################### AUTOENCODER FINETUNING #############################\n",
    "##############################################################################\n",
    "lr = 1e-4\n",
    "l2_decay = 1e-5\n",
    "optimizer = torch.optim.Adam(\n",
    "    [\n",
    "        {\n",
    "            'params': ae.parameters(),\n",
    "        }\n",
    "    ], lr=lr, weight_decay=l2_decay\n",
    ")\n",
    "scaler = GradScaler()\n",
    "\n",
    "tqdm_fmt = ('{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining},'\n",
    "                '{rate_fmt}{postfix}]')\n",
    "tqdm_epoch = {'total': EPOCHS, 'leave': True, 'desc': 'Epochs',\n",
    "              'colour': 'blue', 'bar_format': tqdm_fmt}\n",
    "tqdm_batch = {'total': ft_dataloader._dataset_length()//BATCH_SIZE + 1,\n",
    "              'leave': True, 'desc': 'Batches', 'colour': 'green',\n",
    "              'bar_format': tqdm_fmt}\n",
    "\n",
    "ae.train()\n",
    "with tqdmnotebook(**tqdm_epoch) as pbar_epochs:\n",
    "    for epoch in range(EPOCHS):\n",
    "        with tqdmnotebook(**tqdm_batch) as pbar_batches:\n",
    "            for databatch, i, _ in ft_dataloader:\n",
    "                total_loss = 0\n",
    "                for city, data in databatch.items():\n",
    "                    x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "                    with torch.cuda.amp.autocast():\n",
    "                        x_recons = ae(x, edge_index)\n",
    "                        x = x.reshape(x_recons.shape)\n",
    "                        loss = AE_criterion(x_recons, x)\n",
    "                    total_loss += loss\n",
    "                scaler.scale(total_loss).backward(retain_graph=True)\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "                pbar_batches.update(1)\n",
    "            pbar_epochs.update(1)\n",
    "\n",
    "folder = osp.join('training logs', 'models', exp_id)\n",
    "check_dir(folder)\n",
    "torch.save(ae.state_dict(), osp.join(folder, f'ae_pretrained_2.pth'))\n",
    "\n",
    "ae.eval()\n",
    "errors = {\n",
    "    'MAE': torch.empty(0, device=device, dtype=torch.float16), \n",
    "    'MSE': torch.empty(0, device=device, dtype=torch.float16)\n",
    "}\n",
    "with torch.no_grad(), tqdmnotebook(**tqdm_batch) as pbar_batches:\n",
    "    for databatch, i, _ in test_dataloader:\n",
    "        for city, data in databatch.items():\n",
    "            x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "            batch_size = int(data.ptr.shape[0] - 1)\n",
    "            x_recons = ae(x, edge_index)\n",
    "\n",
    "            x = x.reshape(batch_size, -1)\n",
    "            x_recons = x_recons.reshape(batch_size, -1)\n",
    "\n",
    "            mae = torch.mean(torch.abs(x - x_recons), dim=1)\n",
    "            mse = torch.mean(torch.square(x - x_recons), dim=1)\n",
    "\n",
    "            errors['MAE'] = torch.cat([errors['MAE'], mae], dim=0)\n",
    "            errors['MSE'] = torch.cat([errors['MSE'], mse], dim=0)\n",
    "            \n",
    "        test_losses_dict['Pre-trained w/ 2 source'] = errors\n",
    "        pbar_batches.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6a4804be-8a97-42d2-845c-90882b009ba6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 800x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_losses_boxplot(test_losses_dict, variable=r'Pre-training', \n",
    "                    errors=['MAE', 'MSE'], specs=\"\", save=True, show=True,\n",
    "                    exp_id=exp_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9ab68a-e0c9-4494-b2c7-7cb7c5c08e38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conv_dim=16\n",
    "linear_dim=8\n",
    "num_channels=NUM_CHANNELS\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "activation='tanh'\n",
    "dropout=0.5\n",
    "K_cheb=3\n",
    "\n",
    "\n",
    "test_losses_dict = {}\n",
    "\n",
    "# MODEL WITH ONLY TARGET\n",
    "specs = f'tgt_{conv_dim=}_{linear_dim=}_{activation=}_{num_channels=}_{K_cheb=}_{device=}_{dropout=}'\n",
    "ae = Autoencoder(conv_dim=conv_dim,\n",
    "                 num_channels=num_channels,\n",
    "                 K_cheb=K_cheb,\n",
    "                 device=device,\n",
    "                 activation=activation,\n",
    "                 dropout=dropout,\n",
    "                 linear_dim=linear_dim,\n",
    "                 ).to(device)\n",
    "\n",
    "lr = 5e-3\n",
    "l2_decay = 5e-4\n",
    "\n",
    "optimizer = torch.optim.Adam([\n",
    "    {'params': ae.parameters()},\n",
    "    ], lr=lr, weight_decay=l2_decay)\n",
    "\n",
    "scaler = GradScaler()\n",
    "tqdm_bar_fmt = '{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}{postfix}]'\n",
    "len_train = source_dataloader._dataset_length()//BATCH_SIZE + 1\n",
    "\n",
    "ae.train()\n",
    "\n",
    "train_losses = []\n",
    "\n",
    "# Outer progress bar for epochs\n",
    "with tqdmnotebook(total=EPOCHS_OFFLINE,\n",
    "                  leave=True,\n",
    "                  desc='Epochs',\n",
    "                  colour='blue',\n",
    "                  bar_format=tqdm_bar_fmt) as pbar_epochs:\n",
    "    for epoch in range(EPOCHS_OFFLINE):\n",
    "        with tqdmnotebook(\n",
    "            total=len_train,\n",
    "            leave=True,\n",
    "            desc='Batches',\n",
    "            colour='green',\n",
    "            bar_format=tqdm_bar_fmt) as pbar_batches:\n",
    "            for databatch, i, _ in target_dataloader:\n",
    "                total_loss = 0\n",
    "                for city, data in databatch.items():\n",
    "                    x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "                    with torch.cuda.amp.autocast():\n",
    "                        x_recons = ae(x, edge_index)\n",
    "                        x = x.reshape(x_recons.shape)\n",
    "                        loss = AE_criterion(x_recons, x)\n",
    "                    total_loss += loss\n",
    "                # Scales loss and calls backward() to create scaled gradients\n",
    "                scaler.scale(total_loss).backward(retain_graph=True)\n",
    "\n",
    "                # Unscales gradients and calls optimizer.step()\n",
    "                scaler.step(optimizer)\n",
    "\n",
    "                # Updates the scale for next iteration\n",
    "                scaler.update()\n",
    "                train_losses.append(total_loss.item())\n",
    "                # Zero the gradients\n",
    "                optimizer.zero_grad()\n",
    "                pbar_batches.update(1)\n",
    "        # reconstruction_plot(x, x_recons, specs=specs, save=True, show=True, exp_id=exp_id)\n",
    "        pbar_epochs.update(1)\n",
    "\n",
    "# train_losses_dict['source_plus_tgt'] = train_losses\n",
    "\n",
    "# reconstruction_plot(x, x_recons, specs=specs, save=False, show=True)\n",
    "folder = osp.join('training logs', 'models', exp_id)\n",
    "check_dir(folder)\n",
    "torch.save(ae.state_dict(), osp.join(folder, f'tgt.pth'))\n",
    "    # After all epochs\n",
    "ae.eval()\n",
    "# total_test_loss = 0\n",
    "# test_losses = []\n",
    "errors = {\n",
    "    'MAE': torch.empty(0, device=device, dtype=torch.float16), \n",
    "    'MSE': torch.empty(0, device=device, dtype=torch.float16)\n",
    "}\n",
    "with torch.no_grad():\n",
    "    for databatch, i, _ in targettest_dataloader:\n",
    "        for city, data in databatch.items():\n",
    "            batch_size = int(data.ptr.shape[0] - 1)\n",
    "            x, edge_index = data.x, data.edge_index\n",
    "            x_recons = ae(x, edge_index)\n",
    "\n",
    "            x = x.reshape(batch_size, -1)\n",
    "            x_recons = x_recons.reshape(batch_size, -1)\n",
    "\n",
    "            mae = torch.mean(torch.abs(x - x_recons), dim=1)\n",
    "            mse = torch.mean(torch.square(x - x_recons), dim=1)\n",
    "\n",
    "            errors['MAE'] = torch.cat([errors['MAE'], mae], dim=0)\n",
    "            errors['MSE'] = torch.cat([errors['MSE'], mse], dim=0)\n",
    "\n",
    "test_losses_dict['Target Only'] = errors\n",
    "plot_losses_boxplot(test_losses_dict, variable=r'Training Process', \n",
    "                    errors=['MAE', 'MSE'], specs=\"\", save=False, show=True,\n",
    "                    exp_id=exp_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29593c33-432c-4fb5-8fdb-2cb433a51d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL WITH ONLY TARGET\n",
    "specs = f'source_{conv_dim=}_{linear_dim=}_{activation=}_{num_channels=}_{K_cheb=}_{device=}_{dropout=}'\n",
    "ae = Autoencoder(conv_dim=conv_dim,\n",
    "                 num_channels=num_channels,\n",
    "                 K_cheb=K_cheb,\n",
    "                 device=device,\n",
    "                 activation=activation,\n",
    "                 dropout=dropout,\n",
    "                 linear_dim=linear_dim,\n",
    "                 ).to(device)\n",
    "\n",
    "lr = 1e-4\n",
    "l2_decay = 1e-5\n",
    "\n",
    "optimizer = torch.optim.Adam([\n",
    "    {'params': ae.parameters()},\n",
    "    ], lr=lr, weight_decay=l2_decay)\n",
    "\n",
    "scaler = GradScaler()\n",
    "tqdm_bar_fmt = '{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}{postfix}]'\n",
    "len_train = source_dataloader._dataset_length()//BATCH_SIZE + 1\n",
    "\n",
    "ae.train()\n",
    "# fn = generate_log_name(prefix=\"autoencoder\", fdir=\"training logs\")\n",
    "# log.basicConfig(filename=osp.join('training logs', fn), level=log.INFO)\n",
    "# Initialize lists to store losses\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "test_losses = []\n",
    "\n",
    "# Outer progress bar for epochs\n",
    "with tqdmnotebook(total=EPOCHS_OFFLINE,\n",
    "                  leave=True,\n",
    "                  desc='Epochs',\n",
    "                  colour='blue',\n",
    "                  bar_format=tqdm_bar_fmt) as pbar_epochs:\n",
    "    for epoch in range(EPOCHS_OFFLINE):\n",
    "        with tqdmnotebook(\n",
    "            total=len_train,\n",
    "            leave=True,\n",
    "            desc='Batches',\n",
    "            colour='green',\n",
    "            bar_format=tqdm_bar_fmt) as pbar_batches:\n",
    "            for databatch, i, _ in source_dataloader:\n",
    "                total_loss = 0\n",
    "                for city, data in databatch.items():\n",
    "                    x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "                    with torch.cuda.amp.autocast():\n",
    "                        x_recons = ae(x, edge_index)\n",
    "                        x = x.reshape(x_recons.shape)\n",
    "                        loss = AE_criterion(x_recons, x)\n",
    "                    total_loss += loss\n",
    "                # Scales loss and calls backward() to create scaled gradients\n",
    "                scaler.scale(total_loss).backward(retain_graph=True)\n",
    "\n",
    "                # Unscales gradients and calls optimizer.step()\n",
    "                scaler.step(optimizer)\n",
    "\n",
    "                # Updates the scale for next iteration\n",
    "                scaler.update()\n",
    "                train_losses.append(total_loss.item())\n",
    "                # Zero the gradients\n",
    "                optimizer.zero_grad()\n",
    "                pbar_batches.update(1)\n",
    "        pbar_epochs.update(1)\n",
    "\n",
    "# FINE-TUNING\n",
    "lr = 5e-3\n",
    "l2_decay = 5e-4\n",
    "\n",
    "optimizer = torch.optim.Adam([\n",
    "    {'params': ae.parameters()},\n",
    "    ], lr=lr, weight_decay=l2_decay)\n",
    "\n",
    "scaler = GradScaler()\n",
    "tqdm_bar_fmt = '{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}{postfix}]'\n",
    "len_train = source_dataloader._dataset_length()//BATCH_SIZE + 1\n",
    "\n",
    "ae.train()\n",
    "train_losses = []\n",
    "# Outer progress bar for epochs\n",
    "with tqdmnotebook(total=EPOCHS_OFFLINE,\n",
    "                  leave=True,\n",
    "                  desc='Epochs',\n",
    "                  colour='blue',\n",
    "                  bar_format=tqdm_bar_fmt) as pbar_epochs:\n",
    "    for epoch in range(EPOCHS_OFFLINE):\n",
    "        with tqdmnotebook(\n",
    "            total=len_train,\n",
    "            leave=True,\n",
    "            desc='Batches',\n",
    "            colour='green',\n",
    "            bar_format=tqdm_bar_fmt) as pbar_batches:\n",
    "            for databatch, i, _ in target_dataloader:\n",
    "                total_loss = 0\n",
    "                for city, data in databatch.items():\n",
    "                    x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "                    with torch.cuda.amp.autocast():\n",
    "                        x_recons = ae(x, edge_index)\n",
    "                        x = x.reshape(x_recons.shape)\n",
    "                        loss = AE_criterion(x_recons, x)\n",
    "                    total_loss += loss\n",
    "                # Scales loss and calls backward() to create scaled gradients\n",
    "                scaler.scale(total_loss).backward(retain_graph=True)\n",
    "\n",
    "                # Unscales gradients and calls optimizer.step()\n",
    "                scaler.step(optimizer)\n",
    "\n",
    "                # Updates the scale for next iteration\n",
    "                scaler.update()\n",
    "                train_losses.append(total_loss.item())\n",
    "                # Zero the gradients\n",
    "                optimizer.zero_grad()\n",
    "                pbar_batches.update(1)\n",
    "        # reconstruction_plot(x, x_recons, specs=specs, save=True, show=True, exp_id=exp_id)\n",
    "        pbar_epochs.update(1)\n",
    "\n",
    "# train_losses_dict['source_plus_tgt'] = train_losses\n",
    "\n",
    "# reconstruction_plot(x, x_recons, specs=specs, save=False, show=True)\n",
    "folder = osp.join('training logs', 'models', exp_id)\n",
    "check_dir(folder)\n",
    "torch.save(ae.state_dict(), osp.join(folder, f'source_plus_tgt.pth'))\n",
    "    # After all epochs\n",
    "ae.eval()\n",
    "errors = {\n",
    "    'MAE': torch.empty(0, device=device, dtype=torch.float16), \n",
    "    'MSE': torch.empty(0, device=device, dtype=torch.float16)\n",
    "}\n",
    "with torch.no_grad():\n",
    "    for databatch, i, _ in targettest_dataloader:\n",
    "        for city, data in databatch.items():\n",
    "            batch_size = int(data.ptr.shape[0] - 1)\n",
    "            x, edge_index = data.x, data.edge_index\n",
    "            x_recons = ae(x, edge_index)\n",
    "\n",
    "            x = x.reshape(batch_size, -1)\n",
    "            x_recons = x_recons.reshape(batch_size, -1)\n",
    "\n",
    "            mae = torch.mean(torch.abs(x - x_recons), dim=1)\n",
    "            mse = torch.mean(torch.square(x - x_recons), dim=1)\n",
    "\n",
    "            errors['MAE'] = torch.cat([errors['MAE'], mae], dim=0)\n",
    "            errors['MSE'] = torch.cat([errors['MSE'], mse], dim=0)\n",
    "\n",
    "test_losses_dict['Pre-trained'] = errors\n",
    "plot_losses_boxplot(test_losses_dict, variable=r'Training Process', \n",
    "                    errors=['MAE', 'MSE'], specs=specs, save=True, show=True,\n",
    "                    exp_id=exp_id)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": ".m113",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/:m113"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
