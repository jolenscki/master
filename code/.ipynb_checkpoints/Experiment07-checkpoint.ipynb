{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12b1a78a-7bec-46ea-84f3-26782ab09084",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "os.environ['TORCH_USE_CUDA_DSA']   = \"1\"\n",
    "from os import path as osp\n",
    "# if 'jupyter' in os.getcwd():\n",
    "#     os.chdir(osp.join(os.getcwd(), 'masterarbeit', 'code'))\n",
    "import glob\n",
    "import time\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm as tqdmnotebook\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from typing import Any\n",
    "from typing import Callable\n",
    "from typing import Optional\n",
    "from typing import Tuple\n",
    "from typing import Union\n",
    "from typing import Dict\n",
    "from typing import List\n",
    "from itertools import cycle\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "mpl.rc('axes', unicode_minus=False)\n",
    "preamble = r'\\usepackage{amsmath}'  # LaTeX preamble command\n",
    "mpl.rcParams['text.latex.preamble'] = preamble\n",
    "\n",
    "# import seaborn as sns\n",
    "import networkx as nx\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "import gc\n",
    "\n",
    "# pytorch imports\n",
    "import torch\n",
    "from torch import Tensor, nn, cuda\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import random_split\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "# pytorch geometric imports\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.transforms import Compose\n",
    "\n",
    "# lightning imports\n",
    "from lightning.pytorch.utilities.combined_loader import CombinedLoader\n",
    "\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "from google.cloud import storage\n",
    "\n",
    "import sys\n",
    "# Add the 'code' directory to sys.path to make the  submodules available\n",
    "# sys.path.append('/home/jupyter/masterarbeit/code')\n",
    "\n",
    "from util.utils import generate_log_name\n",
    "from util.plot_utils import *\n",
    "\n",
    "import logging as log\n",
    "\n",
    "from data.dataset.GraphDataset import GraphDataset\n",
    "\n",
    "from model.transform import CollapseChannels, ExtractSquare\n",
    "from model.autoencoder import Autoencoder\n",
    "from model.predictor import Predictor\n",
    "from model.DAN import GradientReversalLayer, DomainDiscriminator\n",
    "\n",
    "from model.criterions import WeightedMSELoss, MSLELoss, FocalLoss, ZeroInflatedLoss, CustomHuberLoss\n",
    "\n",
    "from fullmodel import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83312120-e8ef-4639-a2b5-91cbe8c8c79a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "exp_id='notebook'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3706c5f2-674c-45d5-be60-93b32640da05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NUM_WORKERS: int = 0\n",
    "BATCH_SIZE: int = 2\n",
    "NUM_CHANNELS: int = 2\n",
    "WDW_LENGTH: list = [12, 6]\n",
    "\n",
    "# Constants that I may change a bit during testing\n",
    "tgt: str = 'MELBOURNE'\n",
    "src_list: list = ['ANTWERP']\n",
    "# src_list: list = ['ANTWERP', 'BANGKOK', 'BARCELONA', 'BERLIN', 'CHICAGO', 'ISTANBUL', 'MOSCOW'] # 7 cities\n",
    "EPOCHS: int = 1\n",
    "tgt_data_limit: int = 1680\n",
    "src_data_limit: int = None\n",
    "LOGGING: int = 1\n",
    "\n",
    "if src_data_limit == -1:\n",
    "    src_data_limit = None\n",
    "\n",
    "# Get data from bucket\n",
    "bucket_name = 'cloud-ai-platform-054ad037-69b6-4c4d-94a1-75d2591213c7'\n",
    "bucket_folder = 'data/graphs'\n",
    "local_folder  = 'data/graphs'\n",
    "download_directory(bucket_name, bucket_folder, local_folder)\n",
    "bucket_folder = 'data/raw'\n",
    "local_folder  = 'data/raw'\n",
    "download_directory(bucket_name, bucket_folder, local_folder)\n",
    "\n",
    "bucket_output = 'output/models/'\n",
    "\n",
    "# Constants that I don't intend to change much\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "TRAIN_VAL_TEST_SPLIT = [0.8, 0.1, 0.1]\n",
    "\n",
    "pre_transform = Compose([\n",
    "    CollapseChannels(),\n",
    "    ExtractSquare(50, 'central'),\n",
    "])\n",
    "\n",
    "static_transform = Compose([\n",
    "    ExtractSquare(50, 'central'),\n",
    "])\n",
    "\n",
    "ds_kwargs = {\n",
    "    'root_dir': 'data/raw',\n",
    "    'device': device,\n",
    "    'pre_transform': pre_transform,\n",
    "    'static_transform': static_transform,\n",
    "}\n",
    "\n",
    "# seed generator for DataLoader\n",
    "torch.manual_seed(2311)\n",
    "\n",
    "# Create datasets for each city\n",
    "ds_dict = {}\n",
    "for city in src_list:\n",
    "    ds_dict[city] = GraphDataset(\n",
    "        cities=[city],\n",
    "        limit=src_data_limit,\n",
    "        **ds_kwargs,\n",
    "    )\n",
    "    \n",
    "temp_tgt = GraphDataset(\n",
    "    cities=[tgt],\n",
    "    limit=None,\n",
    "    **ds_kwargs,\n",
    ")\n",
    "\n",
    "train_tgt, val_tgt, test_tgt = random_split(\n",
    "    temp_tgt, [0.08, 0.08, 0.84]\n",
    ")\n",
    "\n",
    "\n",
    "train_tgt = DataLoader(train_tgt, batch_size=BATCH_SIZE, shuffle=True,  drop_last=True)\n",
    "val_tgt   = DataLoader(  val_tgt, batch_size=BATCH_SIZE, shuffle=True,  drop_last=True)\n",
    "test_tgt  = DataLoader( test_tgt, batch_size=BATCH_SIZE, shuffle=False, drop_last=True)\n",
    "# Split each dataset into training and test sets\n",
    "train = {}\n",
    "val   = {}\n",
    "test  = {}\n",
    "for city in ds_dict:\n",
    "    train_ds, val_ds, test_ds = random_split(\n",
    "        ds_dict[city], TRAIN_VAL_TEST_SPLIT\n",
    "    )\n",
    "    train[city] = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,  drop_last=True)\n",
    "    val[city]   = DataLoader(  val_ds, batch_size=BATCH_SIZE, shuffle=True,  drop_last=True)\n",
    "    test[city]  = DataLoader( test_ds, batch_size=BATCH_SIZE, shuffle=False, drop_last=True)\n",
    "\n",
    "train[tgt] = train_tgt\n",
    "val[tgt]   = val_tgt\n",
    "test[tgt]  = test_tgt\n",
    "\n",
    "# Create dataloader for offline training with source cities\n",
    "source_train = {city: train[city] for city in src_list}\n",
    "source_dataloader = CombinedLoader(source_train, mode='max_size_cycle')\n",
    "\n",
    "source_test = {city: test[city] for city in src_list}\n",
    "sourcetest_dataloader = CombinedLoader(source_test, mode='max_size_cycle')\n",
    "\n",
    "target_dataloader = CombinedLoader({tgt: train[tgt]}, mode='max_size_cycle')\n",
    "targettest_dataloader = CombinedLoader({tgt: test[tgt]}, mode='max_size_cycle')\n",
    "\n",
    "# Create dataloader for online training with source and target cities\n",
    "train_dataloader = CombinedLoader(train, mode='max_size_cycle')\n",
    "\n",
    "# Create dataloader for validation with source and target cities\n",
    "val_dataloader = CombinedLoader(val, mode='max_size_cycle')\n",
    "\n",
    "# Create dataloader for testing with source and target cities\n",
    "test_dataloader = CombinedLoader(test, mode='max_size_cycle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5eca4083-1f0b-4d20-a86d-8c9d13a17c65",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1cd83f7c35d4d6293782db104572645",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/1 [00:00<?,?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<tqdm.notebook.tqdm_notebook at 0x7f9ce9756020>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "652e35e527a34cf688b422c82d354352",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/34561 [00:00<?,?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<tqdm.notebook.tqdm_notebook at 0x7f9ce859ca00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Expected more than 1 value per channel when training, got input size torch.Size([1, 14000])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 76\u001b[0m\n\u001b[1;32m     57\u001b[0m test_errors \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     59\u001b[0m model \u001b[38;5;241m=\u001b[39m Model(\n\u001b[1;32m     60\u001b[0m     AE_parameters\u001b[38;5;241m=\u001b[39mAE_parameters,\n\u001b[1;32m     61\u001b[0m     DD_parameters\u001b[38;5;241m=\u001b[39mDD_parameters,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     73\u001b[0m     val_dl\u001b[38;5;241m=\u001b[39mval_dataloader\n\u001b[1;32m     74\u001b[0m )\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 76\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mae_train\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpretrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m model\u001b[38;5;241m.\u001b[39mae_train(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinetune\u001b[39m\u001b[38;5;124m'\u001b[39m, save\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     79\u001b[0m model\u001b[38;5;241m.\u001b[39mpred_train(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpretrain\u001b[39m\u001b[38;5;124m'\u001b[39m, save\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/masterarbeit/code/fullmodel.py:129\u001b[0m, in \u001b[0;36mModel.ae_train\u001b[0;34m(self, mode, lambda_update, save, plot)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m city \u001b[38;5;129;01min\u001b[39;00m [selected_city, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtgt] \u001b[38;5;129;01mand\u001b[39;00m dd_lambda \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    128\u001b[0m         H \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mGRL(H)\n\u001b[0;32m--> 129\u001b[0m         dd_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m            \u001b[49m\u001b[43mH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcity\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtgt\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m         total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m dd_lambda \u001b[38;5;241m*\u001b[39m dd_loss\n\u001b[1;32m    133\u001b[0m \u001b[38;5;66;03m#############################################\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/masterarbeit/code/model/DAN.py:128\u001b[0m, in \u001b[0;36mDomainDiscriminator.forward\u001b[0;34m(self, features, edge_index, batch, city, tgt, return_logits)\u001b[0m\n\u001b[1;32m    125\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39munique()\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    126\u001b[0m x_ \u001b[38;5;241m=\u001b[39m x_\u001b[38;5;241m.\u001b[39mview(batch_size, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 128\u001b[0m x_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    129\u001b[0m x_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(x_)\n\u001b[1;32m    131\u001b[0m \u001b[38;5;66;03m# shape of domain_logits: (batch_size, 1)\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:171\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    164\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:2448\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2435\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m   2436\u001b[0m         batch_norm,\n\u001b[1;32m   2437\u001b[0m         (\u001b[38;5;28minput\u001b[39m, running_mean, running_var, weight, bias),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2445\u001b[0m         eps\u001b[38;5;241m=\u001b[39meps,\n\u001b[1;32m   2446\u001b[0m     )\n\u001b[1;32m   2447\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[0;32m-> 2448\u001b[0m     \u001b[43m_verify_batch_size\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2450\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mbatch_norm(\n\u001b[1;32m   2451\u001b[0m     \u001b[38;5;28minput\u001b[39m, weight, bias, running_mean, running_var, training, momentum, eps, torch\u001b[38;5;241m.\u001b[39mbackends\u001b[38;5;241m.\u001b[39mcudnn\u001b[38;5;241m.\u001b[39menabled\n\u001b[1;32m   2452\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:2416\u001b[0m, in \u001b[0;36m_verify_batch_size\u001b[0;34m(size)\u001b[0m\n\u001b[1;32m   2414\u001b[0m     size_prods \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m size[i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m   2415\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_prods \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m-> 2416\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected more than 1 value per channel when training, got input size \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(size))\n",
      "\u001b[0;31mValueError\u001b[0m: Expected more than 1 value per channel when training, got input size torch.Size([1, 14000])"
     ]
    }
   ],
   "source": [
    "##############################################################################\n",
    "########################## INSTANTIATING THE MODEL ###########################\n",
    "##############################################################################\n",
    "AE_K_CHEB = 3\n",
    "AE_CONV_DIM = 16\n",
    "AE_LINEAR_DIM = 8\n",
    "AE_DROPOUT = 0.5\n",
    "AE_ACTIVATION = 'tanh'\n",
    "\n",
    "AE_parameters = {\n",
    "    'K_cheb': AE_K_CHEB,\n",
    "    'conv_dim': AE_CONV_DIM,\n",
    "    'linear_dim': AE_LINEAR_DIM,\n",
    "    'dropout': AE_DROPOUT,\n",
    "    'activation': AE_ACTIVATION,\n",
    "    'num_channels': NUM_CHANNELS,\n",
    "    'device': device,\n",
    "}\n",
    "\n",
    "DD_SEQ_LEN = 12\n",
    "DD_FEAT_DIM = AE_LINEAR_DIM\n",
    "DD_LEFT_NODES = 1750\n",
    "DD_parameters = {\n",
    "    'seq_len': DD_SEQ_LEN,\n",
    "    'feat_dim': DD_FEAT_DIM,\n",
    "    'left_nodes': DD_LEFT_NODES,\n",
    "}\n",
    "\n",
    "# autoencoder linear dims + 4 sin-cos time features\n",
    "PRED_FEATURES   = AE_LINEAR_DIM + 4\n",
    "PRED_LINEAR_DIM = 32\n",
    "PRED_PERIODS_IN = 12\n",
    "PRED_PERIODS_OUT = [0, 1, 2, 5, 8, 11]\n",
    "PRED_ACTIVATION  = 'relu'\n",
    "\n",
    "PR_parameters = {\n",
    "    'features': PRED_FEATURES,\n",
    "    'linear_dim': PRED_LINEAR_DIM,\n",
    "    'periods_in': PRED_PERIODS_IN,\n",
    "    'periods_out': PRED_PERIODS_OUT,\n",
    "    'activation': PRED_ACTIVATION,\n",
    "    'num_channels': NUM_CHANNELS,\n",
    "    'device': device,\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    \n",
    "}\n",
    "num_epochs = EPOCHS\n",
    "dataloaders = train_dataloader, target_dataloader, targettest_dataloader\n",
    "AE_criterion = nn.MSELoss()\n",
    "PR_criterion = nn.MSELoss()\n",
    "optimizer_parameters = 5e-4, 5e-5\n",
    "BATCH_SIZE = BATCH_SIZE\n",
    "dd_lambda = 1e-3\n",
    "\n",
    "folder = osp.join('training logs', 'models', exp_id)\n",
    "check_dir(folder)\n",
    "test_errors = {}\n",
    "\n",
    "model = Model(\n",
    "    AE_parameters=AE_parameters,\n",
    "    DD_parameters=DD_parameters,\n",
    "    PR_parameters=PR_parameters,\n",
    "    num_epochs=1,\n",
    "    dataloaders=dataloaders,\n",
    "    AE_criterion=AE_criterion,\n",
    "    PR_criterion=PR_criterion,\n",
    "    optimizer_parameters=optimizer_parameters,\n",
    "    BATCH_SIZE=BATCH_SIZE,\n",
    "    dd_lambda=dd_lambda,\n",
    "    folder=folder,\n",
    "    specs=f'',\n",
    "    tgt=tgt,\n",
    "    val_dl=val_dataloader\n",
    ").to(device)\n",
    "\n",
    "model.ae_train('pretrain', save=False)\n",
    "model.ae_train('finetune', save=True)\n",
    "\n",
    "model.pred_train('pretrain', save=False)\n",
    "model.pred_train('finetune', save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfdbdbb-5044-446b-8138-5f9bf83340b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": ".m113",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/:m113"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
