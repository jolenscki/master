{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12b1a78a-7bec-46ea-84f3-26782ab09084",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "os.environ['TORCH_USE_CUDA_DSA']   = \"1\"\n",
    "from os import path as osp\n",
    "# if 'jupyter' in os.getcwd():\n",
    "#     os.chdir(osp.join(os.getcwd(), 'masterarbeit', 'code'))\n",
    "import glob\n",
    "import time\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm as tqdmnotebook\n",
    "\n",
    "import multiprocessing as mp\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from typing import Any\n",
    "from typing import Callable\n",
    "from typing import Optional\n",
    "from typing import Tuple\n",
    "from typing import Union\n",
    "from typing import Dict\n",
    "from typing import List\n",
    "from itertools import cycle\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "mpl.rc('axes', unicode_minus=False)\n",
    "preamble = r'\\usepackage{amsmath}'  # LaTeX preamble command\n",
    "mpl.rcParams['text.latex.preamble'] = preamble\n",
    "\n",
    "# import seaborn as sns\n",
    "import networkx as nx\n",
    "import math\n",
    "import numpy as np\n",
    "import random\n",
    "import gc\n",
    "\n",
    "# pytorch imports\n",
    "import torch\n",
    "from torch import Tensor, nn, cuda\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import random_split\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "# pytorch geometric imports\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.transforms import Compose\n",
    "\n",
    "# lightning imports\n",
    "from lightning.pytorch.utilities.combined_loader import CombinedLoader\n",
    "\n",
    "from google.cloud import storage\n",
    "\n",
    "import sys\n",
    "# Add the 'code' directory to sys.path to make the  submodules available\n",
    "# sys.path.append('/home/jupyter/masterarbeit/code')\n",
    "\n",
    "from util.utils import generate_log_name\n",
    "from util.plot_utils import *\n",
    "\n",
    "import logging as log\n",
    "\n",
    "from data.dataset.GraphDataset import GraphDataset\n",
    "\n",
    "from model.transform import CollapseChannels, ExtractSquare\n",
    "from model.autoencoder import Autoencoder\n",
    "from model.predictor import Predictor\n",
    "from model.DAN import GradientReversalLayer, DomainDiscriminator\n",
    "\n",
    "from model.criterions import WeightedMSELoss, MSLELoss, FocalLoss, ZeroInflatedLoss, CustomHuberLoss\n",
    "from model.baselines import HAPredictor, ConvLSTMPredictor\n",
    "\n",
    "from fullmodel import Model\n",
    "\n",
    "from statsmodels.tsa.arima.model import ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83312120-e8ef-4639-a2b5-91cbe8c8c79a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "exp_id='baselines'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3706c5f2-674c-45d5-be60-93b32640da05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NUM_CHANNELS: int = 2\n",
    "WDW_LENGTH: list = [12, 6]\n",
    "N_weeks=2\n",
    "BATCH_SIZE=2\n",
    "EPOCHS=2\n",
    "\n",
    "# Constants that I may change a bit during testing\n",
    "tgt: str = 'MELBOURNE'\n",
    "\n",
    "# Constants that I don't intend to change much\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device('cpu')\n",
    "\n",
    "pre_transform = Compose([\n",
    "    CollapseChannels(),\n",
    "])\n",
    "\n",
    "\n",
    "ds_kwargs = {\n",
    "    'root_dir': 'data/raw',\n",
    "    'device': device,\n",
    "    'pre_transform': pre_transform,\n",
    "}\n",
    "\n",
    "# seed generator for DataLoader\n",
    "torch.manual_seed(2311)\n",
    "\n",
    "TRAIN_VAL_TEST_SPLIT_TGT = [\n",
    "        N_weeks*0.04,\n",
    "        0.04,\n",
    "        1 - (N_weeks+1)*0.04\n",
    "    ]\n",
    "\n",
    "gs = GraphDataset(\n",
    "    cities=[tgt],\n",
    "    limit=None,\n",
    "    **ds_kwargs,\n",
    ")\n",
    "\n",
    "train, val, test = random_split(\n",
    "    gs, TRAIN_VAL_TEST_SPLIT_TGT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3650fdcf-9f36-4127-a0e6-60b15f8bca94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dl   = DataLoader(  val, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dl  = DataLoader( test, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79500743-093b-424e-89c7-a11b8d3459b0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "hidden_dims = [8, 16, 32, 64, 16, 2]\n",
    "num_layers = len(hidden_dims)\n",
    "kernel_size=3\n",
    "\n",
    "model = ConvLSTMPredictor(\n",
    "    num_channels=NUM_CHANNELS, \n",
    "    hidden_dims=hidden_dims, \n",
    "    kernel_size=kernel_size, \n",
    "    num_layers=num_layers,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b784b1e9-0602-4aa1-969b-35ef1fd6a8c3",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "lr = 5e-6\n",
    "l2_decay = 5e-7\n",
    "crit = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(\n",
    "    [\n",
    "        {'params': model.parameters()},\n",
    "    ], lr=lr, weight_decay=l2_decay\n",
    ")\n",
    "scaler = GradScaler()\n",
    "tqdm_fmt = ('{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining},'\n",
    "        '{rate_fmt}{postfix}]')\n",
    "tqdm_epoch = {'total': EPOCHS, 'leave': True, 'desc': 'Epochs',\n",
    "              'colour': 'blue', 'bar_format': tqdm_fmt}\n",
    "tqdm_batch = {'total': len(train_dl),\n",
    "              'leave': True, 'desc': 'Batches', 'colour': 'green',\n",
    "              'bar_format': tqdm_fmt}\n",
    " # Initialize the progress bars\n",
    "pbar_epochs = tqdmnotebook(**tqdm_epoch)\n",
    "epoch_handle = display(pbar_epochs, display_id='pbar_epoch')\n",
    "pbar_batches = tqdmnotebook(**tqdm_batch)\n",
    "batch_handle = display(pbar_batches, display_id='pbar_batch')\n",
    "train_losses = []\n",
    "\n",
    "step = 64 // BATCH_SIZE\n",
    "model.train()\n",
    "for epoch in range(EPOCHS):\n",
    "    optimizer.zero_grad()\n",
    "    for i, db in enumerate(train_dl):\n",
    "        total_loss = torch.tensor(0., device=device)\n",
    "        x, y = db.x, db.y\n",
    "        x = gs.graph_to_image(tgt, x.view(-1, NUM_CHANNELS, WDW_LENGTH[0]))\n",
    "        y = gs.graph_to_image(tgt, y.view(-1, NUM_CHANNELS, WDW_LENGTH[1]))\n",
    "        \n",
    "        x = torch.movedim(x, -1, 2)\n",
    "        y = torch.movedim(y, -1, 2)\n",
    "        \n",
    "        with torch.cuda.amp.autocast():\n",
    "            y_hat = model(x)\n",
    "            loss = crit(y_hat, y)\n",
    "        scaled_loss = scaler.scale(loss)\n",
    "        train_losses.append(loss.detach().cpu().numpy())\n",
    "        scaled_loss.backward()\n",
    "        if (i + 1) % step == 0 or (i+1) == len(train_dl):\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()               \n",
    "            optimizer.zero_grad()\n",
    "        if i%25 == 0:\n",
    "            loss_per_epoch(\n",
    "                train_losses, epoch+1, specs=\"\",\n",
    "                save=False\n",
    "            )\n",
    "        \n",
    "        pbar_batches.update(1)\n",
    "    pbar_batches.reset()\n",
    "    pbar_epochs.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361f95f0-7d5e-432d-9111-1c4be6739c47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_crit(crit, y, y_hat):\n",
    "    '''\n",
    "    Calculate various error metrics between actual and predicted values.\n",
    "    This method supports MAE, MSE, MAPE, and RMSE.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    crit: {'MAE', 'MSE', 'MAPE', 'RMSE'}\n",
    "        the criterion to use for calculating the error\n",
    "    y: torch.Tensor\n",
    "        the actual values, of shape (N, *) with N being the batch size\n",
    "    y_hat: torch.Tensor\n",
    "        the predicted values, of same shape as `y`\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    torch.Tensor\n",
    "        the calculated error based on the specified criterion, of shape\n",
    "        (N, )\n",
    "    '''\n",
    "    if crit == 'MAE':\n",
    "        return torch.mean(torch.abs(y - y_hat), dim=1)\n",
    "    elif crit == 'MSE':\n",
    "        return torch.mean(torch.square(y - y_hat), dim=1)\n",
    "    elif crit == 'MAPE':\n",
    "        epsilon = 1e-8  # Small constant to avoid division by zero\n",
    "        return torch.mean(torch.abs((y - y_hat) / (y + epsilon)), dim=1) * 100\n",
    "    elif crit == 'RMSE':\n",
    "        return torch.sqrt(torch.mean(torch.square(y - y_hat), dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75a03c3-85d2-4184-aba9-15020f5fd83a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_limit = 1000//BATCH_SIZE\n",
    "crit = ['MAE', 'RMSE']\n",
    "errors = {k: torch.empty(0, device=device, dtype=torch.float16)\n",
    "                 for k in crit}\n",
    "if sample_limit == -1:\n",
    "    sample_limit = len(test_dl)\n",
    "\n",
    "tqdm_fmt = ('{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining},'\n",
    "        '{rate_fmt}{postfix}]')\n",
    "tqdm_batch = {'total': sample_limit,\n",
    "              'leave': True, 'desc': 'Batches', 'colour': 'green',\n",
    "              'bar_format': tqdm_fmt}\n",
    "pbar_batches = tqdmnotebook(**tqdm_batch)\n",
    "batch_handle = display(pbar_batches, display_id='pbar_batch')\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, db in enumerate(test_dl):\n",
    "        x, y = db.x, db.y\n",
    "        x = gs.graph_to_image(tgt, x.view(-1, NUM_CHANNELS, WDW_LENGTH[0]))\n",
    "        y = gs.graph_to_image(tgt, y.view(-1, NUM_CHANNELS, WDW_LENGTH[1]))\n",
    "\n",
    "        x = torch.movedim(x, -1, 2)\n",
    "        y = torch.movedim(y, -1, 2)\n",
    "        \n",
    "        y /= 255\n",
    "\n",
    "        y_hat = model(x)\n",
    "        \n",
    "        y = y.reshape(BATCH_SIZE, -1)\n",
    "        y_hat = y_hat.reshape(BATCH_SIZE, -1)\n",
    "        \n",
    "        for c in crit:\n",
    "            errors[c] = torch.cat(\n",
    "                [errors[c], calculate_crit(c, y, y_hat)],\n",
    "                dim=0\n",
    "            ).detach()\n",
    "        \n",
    "        if i > sample_limit:\n",
    "            break\n",
    "        \n",
    "        pbar_batches.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5f64d1f3-8162-434d-9c4b-82a0b2a978e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = gs\n",
    "N = 2\n",
    "predict_window = 10\n",
    "hap = HistoricalAveragePredictor(dataset=dataset, N=N, predict_window=predict_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4f473c7e-ad9c-4cb2-b08d-60cb57a95280",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ARIMAPredictor:\n",
    "    def __init__(self, dataset, N, predict_window, order, num_channels=2, random_start=False):\n",
    "        self.dataset = dataset\n",
    "        self.N = N\n",
    "        self.predict_window = predict_window if predict_window is not None else len(dataset) // (240 * 7) - N\n",
    "        self.order = order\n",
    "        self.num_channels = num_channels\n",
    "        self.random_start = random_start\n",
    "        self.num_nodes, _ = self.dataset[0].x.shape\n",
    "        self.snapshots = _ // self.num_channels\n",
    "\n",
    "    def get_past_datapoints(self, index):\n",
    "        past_indices = [index - 240 * 7 * week for week in range(1, self.N + 1)]\n",
    "        past_datapoints = [self.dataset[i].x.view(-1, self.num_channels, self.snapshots) for i in past_indices]\n",
    "        stacked_past = torch.stack(past_datapoints).numpy()\n",
    "        return stacked_past\n",
    "\n",
    "    def fit_predict_arima(self, node_channel_snapshot_data):\n",
    "        node, channel, snapshot, past_datapoints = node_channel_snapshot_data\n",
    "        model = ARIMA(past_datapoints, order=self.order)\n",
    "        model_fit = model.fit()\n",
    "        fc = model_fit.forecast(steps=1)[0]\n",
    "        return node, channel, snapshot, fc\n",
    "\n",
    "    def predict(self):\n",
    "        crit = ['MAE', 'RMSE']\n",
    "        errors = {k: torch.empty(0, device='cpu', dtype=torch.float16) for k in crit}\n",
    "        ds_start = 240 * 7 * self.N\n",
    "        ds_end = ds_start + 240 * 7 * self.predict_window\n",
    "\n",
    "        if self.random_start:\n",
    "            ds_start = random.randint(ds_start, len(self.dataset) - 240 * 7 * self.predict_window)\n",
    "            print(f'Random start: {ds_start}')\n",
    "\n",
    "        tqdm_args = {'total': ds_end - ds_start, 'leave': True, 'desc': 'Predicting', 'colour': 'blue'}\n",
    "        pbar = tqdm(**tqdm_args)\n",
    "\n",
    "        # Parallel processing setup\n",
    "        pool = mp.Pool(1)\n",
    "        for i in range(ds_start, ds_end):\n",
    "            actual = self.dataset[i].x.view(-1, self.num_channels, self.snapshots).numpy()\n",
    "            prediction = np.zeros_like(actual)\n",
    "\n",
    "            # Prepare data for parallel processing\n",
    "            parallel_data = []\n",
    "            for node in range(self.num_nodes):\n",
    "                print(node)\n",
    "                for channel in range(self.num_channels):\n",
    "                    for snapshot in range(self.snapshots):\n",
    "                        past_datapoints = self.get_past_datapoints(i)[:, node, channel, snapshot]\n",
    "                        parallel_data.append((node, channel, snapshot, past_datapoints))\n",
    "            # Parallel ARIMA fitting and forecasting\n",
    "            forecasts = pool.map(self.fit_predict_arima, parallel_data)\n",
    "            for node, channel, snapshot, fc in forecasts:\n",
    "                prediction[node, channel, snapshot] = fc\n",
    "\n",
    "            for c in crit:\n",
    "                errors[c] = torch.cat([errors[c], self.calculate_crit(c, actual, prediction)], dim=0).detach()\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "        \n",
    "        return errors\n",
    "                                       \n",
    "    @staticmethod\n",
    "    def calculate_crit(crit, y, y_hat):\n",
    "        '''\n",
    "        Calculate various error metrics between actual and predicted values.\n",
    "        This method supports MAE, MSE, MAPE, and RMSE.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        crit: {'MAE', 'MSE', 'MAPE', 'RMSE'}\n",
    "            the criterion to use for calculating the error\n",
    "        y: np.ndarray\n",
    "            the actual values, of shape (N, *) with N being the batch size\n",
    "        y_hat: np.ndarray\n",
    "            the predicted values, of same shape as `y`\n",
    "    \n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            the calculated error based on the specified criterion, of shape\n",
    "            (N, )\n",
    "        '''\n",
    "        y = torch.tensor(y)\n",
    "        y_hat = torch.tensor(y_hat)\n",
    "        if crit == 'MAE':\n",
    "            return torch.mean(torch.abs(y - y_hat), dim=1)\n",
    "        elif crit == 'MSE':\n",
    "            return torch.mean(torch.square(y - y_hat), dim=1)\n",
    "        elif crit == 'MAPE':\n",
    "            epsilon = 1e-8  # Small constant to avoid division by zero\n",
    "            return torch.mean(torch.abs((y - y_hat) / (y + epsilon)), dim=1) * 100\n",
    "        elif crit == 'RMSE':\n",
    "            return torch.sqrt(torch.mean(torch.square(y - y_hat), dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "09d92c86-860c-439b-be3d-52a9673b34bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random start: 15562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Predicting: 0it [00:00, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n"
     ]
    }
   ],
   "source": [
    "dataset = gs\n",
    "N = 2\n",
    "predict_window=1\n",
    "\n",
    "arima = ARIMAPredictor(\n",
    "    dataset=dataset,\n",
    "    N=N,\n",
    "    predict_window=predict_window,\n",
    "    order=(0, 2, 2),\n",
    "    random_start=True\n",
    ")\n",
    "\n",
    "errors = arima.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bf18fb75-a72b-4a07-9046-f541b1988156",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9adecc152ca24a16ab13c1a4cf31f1cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:  67%|######6   | 3360/5040 [00:00<?,?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<tqdm.notebook.tqdm_notebook at 0x7f19c5eb01f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from model.baselines import HAPredictor\n",
    "from typing import Union, List\n",
    "import torch\n",
    "from torch import nn\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm as tqdmnotebook\n",
    "import numpy as np\n",
    "\n",
    "class HAPredictor:\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset,\n",
    "        N,\n",
    "        predict_window,\n",
    "    ):\n",
    "        '''\n",
    "        Parameters\n",
    "        ----------\n",
    "        dataset : GraphDataset\n",
    "        N : int\n",
    "            number of weeks to consider\n",
    "        predict_window : int\n",
    "            number of weeks to predict\n",
    "        '''\n",
    "        self.dataset = dataset\n",
    "        self.N = N  # number of weeks to consider\n",
    "        if predict_window is None or predict_window == -1:\n",
    "            self.predict_window = len(dataset) // (240*7) - N\n",
    "        else:\n",
    "            self.predict_window = predict_window\n",
    "\n",
    "    def get_past_datapoints(self, index):\n",
    "        past_indices = [index - 240 * 7 * week for week in range(1, self.N + 1)]\n",
    "        past_datapoints = [self.dataset[i].x for i in past_indices]\n",
    "        stacked_past = torch.stack(past_datapoints).numpy()\n",
    "        \n",
    "        return stacked_past\n",
    "\n",
    "    def predict(self):\n",
    "        predictions = []\n",
    "        crit = ['MAE', 'RMSE']\n",
    "        errors = {k: torch.empty(0, device='cpu', dtype=torch.float16)\n",
    "                 for k in crit}\n",
    "        \n",
    "        ds_start = 240*7*self.N\n",
    "        ds_end   = int(240*7*(self.N+self.predict_window))\n",
    "        \n",
    "        tqdm_fmt = ('{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining},'\n",
    "                '{rate_fmt}{postfix}]')\n",
    "        tqdm_args = {'total': ds_end, 'leave': True, 'desc': 'Epochs',\n",
    "                      'colour': 'blue', 'bar_format': tqdm_fmt, 'initial': ds_start}\n",
    "        \n",
    "        # Initialize the progress bars\n",
    "        pbar = tqdmnotebook(**tqdm_args)\n",
    "        epoch_handle = display(pbar, display_id='pbar')\n",
    "\n",
    "        # Start from the Nth week to ensure we have past data\n",
    "        # for i in range(240 * 7 * self.N, len(self.dataset)):\n",
    "        for i in range(ds_start, ds_end):\n",
    "            past_datapoints = self.get_past_datapoints(i)\n",
    "            prediction = np.mean(past_datapoints, axis=0)\n",
    "            actual = self.dataset[i].x.numpy()\n",
    "            actual_nonzero = actual[actual.nonzero()]\n",
    "            pred_nonzero   = prediction[actual.nonzero()]\n",
    "\n",
    "            for c in crit:\n",
    "                metric = self.calculate_crit(c, actual_nonzero, pred_nonzero)\n",
    "                errors[c] = torch.cat(\n",
    "                    [\n",
    "                        errors[c],\n",
    "                        metric.reshape(1)\n",
    "                    ],\n",
    "                dim=0).detach()\n",
    "            pbar.update(1)\n",
    "\n",
    "        return errors\n",
    "                                       \n",
    "    @staticmethod\n",
    "    def calculate_crit(crit, y, y_hat):\n",
    "        '''\n",
    "        Calculate various error metrics between actual and predicted values.\n",
    "        This method supports MAE, MSE, MAPE, and RMSE.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        crit: {'MAE', 'MSE', 'MAPE', 'RMSE'}\n",
    "            the criterion to use for calculating the error\n",
    "        y: np.ndarray\n",
    "            the actual values, of shape (N, *) with N being the batch size\n",
    "        y_hat: np.ndarray\n",
    "            the predicted values, of same shape as `y`\n",
    "    \n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            the calculated error based on the specified criterion, of shape\n",
    "            (N, )\n",
    "        '''\n",
    "        y = torch.tensor(y)\n",
    "        y_hat = torch.tensor(y_hat)\n",
    "        assert y.shape == y_hat.shape, \"Misshape\"\n",
    "        if crit == 'MAE':\n",
    "            return torch.mean(torch.abs(y - y_hat), dim=0)\n",
    "        elif crit == 'MSE':\n",
    "            return torch.mean(torch.square(y - y_hat), dim=1)\n",
    "        elif crit == 'MAPE':\n",
    "            epsilon = 1e-8  # Small constant to avoid division by zero\n",
    "            return torch.mean(torch.abs((y - y_hat) / (y + epsilon)), dim=1) * 100\n",
    "        elif crit == 'RMSE':\n",
    "            return torch.sqrt(torch.mean(torch.square(y - y_hat), dim=0))\n",
    "\n",
    "# Usage\n",
    "dataset = gs\n",
    "N = 2\n",
    "hap = HAPredictor(dataset, N, predict_window=1)\n",
    "errors = hap.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b04f0208-33a3-4d08-80d2-16cace1ce63a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0888)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors['MAE'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "df65be89-6a71-4549-bf80-80484dc33c99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1150)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors['RMSE'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7ed27e8a-9916-46d1-bbdd-f1cc8828d11b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors['MAE'][12323323]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "953d6407-b3be-4484-9fb9-0cb39f92712f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4177236"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "64ea538a-5c66-46ac-945a-9a56640440ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21177497657780428"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(torch.count_nonzero(errors['MAE']))/int(errors['MAE'].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8111fe-472c-44cf-8685-567feda74b95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": ".m113",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/:m113"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0a519b0916fd4791857cad8cb1fdad6e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_c58276a687004c828412668f8045c13e",
       "style": "IPY_MODEL_0f2d720698354676be4cddde2fa75d5c",
       "value": "Epochs:   0%"
      }
     },
     "0f2d720698354676be4cddde2fa75d5c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "1a291459d7b545c697fa58b69cd8a590": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "25ce23bc00ba47e0b64c85b5252e8313": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "4758b0e29a7d4d03b00da3dbdeb48e47": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "bar_color": "green",
       "description_width": ""
      }
     },
     "7392bb7f0ca04363b5e344af101b7f6b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "layout": "IPY_MODEL_d9a8b8d0ffb74c5c99ff20c71715f23a",
       "max": 1728,
       "style": "IPY_MODEL_4758b0e29a7d4d03b00da3dbdeb48e47",
       "value": 558
      }
     },
     "878fd89ff5ef4ca6b56afbbb4e8f7eb8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "89d6f663d72443a8a1c4a276a481e273": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "8cc4f6dc8746493ebc700758e0abcd88": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "8f54fe238de645c6adcc80741412c29f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_0a519b0916fd4791857cad8cb1fdad6e",
        "IPY_MODEL_fb4619fb35f3454ab08f50e57989c360",
        "IPY_MODEL_abc02e985cc245af8a627bcf0202f075"
       ],
       "layout": "IPY_MODEL_878fd89ff5ef4ca6b56afbbb4e8f7eb8"
      }
     },
     "9dccad280b70465db31a48542eca3824": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_1a291459d7b545c697fa58b69cd8a590",
       "style": "IPY_MODEL_f72fa865ee834627be8fcadaa0e3af4a",
       "value": " 558/1728 [35:32&lt;1:15:12, 3.86s/it]"
      }
     },
     "9e1f34671b9b473b80d3cf07f5e3c33f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "bar_color": "blue",
       "description_width": ""
      }
     },
     "a794abdf114c4de8918ab21bd1cac909": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "abc02e985cc245af8a627bcf0202f075": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_25ce23bc00ba47e0b64c85b5252e8313",
       "style": "IPY_MODEL_8cc4f6dc8746493ebc700758e0abcd88",
       "value": " 0/2 [00:00&lt;?,?it/s]"
      }
     },
     "ae84d5daf7d24154b83f530f3f0c3761": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "ba9fad6fc9ea421d93dcee6bfec71037": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_89d6f663d72443a8a1c4a276a481e273",
       "style": "IPY_MODEL_ae84d5daf7d24154b83f530f3f0c3761",
       "value": "Batches:  32%"
      }
     },
     "c58276a687004c828412668f8045c13e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c81d08aa41774490a8eb31dd99fd3fa9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_ba9fad6fc9ea421d93dcee6bfec71037",
        "IPY_MODEL_7392bb7f0ca04363b5e344af101b7f6b",
        "IPY_MODEL_9dccad280b70465db31a48542eca3824"
       ],
       "layout": "IPY_MODEL_a794abdf114c4de8918ab21bd1cac909"
      }
     },
     "d29d2e1f0ce84c6fabe8a231d9769831": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "d9a8b8d0ffb74c5c99ff20c71715f23a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f72fa865ee834627be8fcadaa0e3af4a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "fb4619fb35f3454ab08f50e57989c360": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "layout": "IPY_MODEL_d29d2e1f0ce84c6fabe8a231d9769831",
       "max": 2,
       "style": "IPY_MODEL_9e1f34671b9b473b80d3cf07f5e3c33f"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
